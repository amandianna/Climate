# -*- coding: utf-8 -*-
"""ROI.TCC.PCA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eJ31pFRSqkpl_SxuQShMZwQPtTXcsq2s

## Principal Component Analysis

Este é um notebook para testarmos um pouco de Python e produzir uma PCA usando o scikit-learn (https://scikit-learn.org/stable/auto_examples/index.html#tutorial-exercises)<br>

## Parte 1 - Garanta que você tem todos os dados

Basicamente estamos lendo os dados aqui e verificando se está tudo certo para a PCA
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # primeiro, seguindo as instruções, eu estou instalando o scikit
# !pip install -U scikit-learn

# Acessando os meus dados no drive
!gdown 19a_ChYss0C0ufvEAnPgiMy2Nl2RR68ac

# agora, preciso apenas apontar para os meus dados
import pandas as pd

df = pd.read_excel('roi_tcc_df_pca.xlsx')
#lembrando que o resultado fica gravado na tabela df (ou seja, um DataFrame)

df.head()

import matplotlib.pyplot as plt
plt.plot(df.ano,df.anomalia_soc,'-ok')
#plt.plot(df.ano,(df.Rendimento.rolling(5).std())**2,'-ob')
plt.xlim([1985,2021])

print(f'A minha anomalia média de SOC para a serie historia é de {df[df.ano>=1985].anomalia_soc.mean()}')

"""Fazendo uma média móvel do SOC

A função Pandas 'dataframe.rolling()' fornece o recurso de cálculos de janela móvel. O conceito de cálculo de janela móvel é usado principalmente no processamento de sinais e dados de séries temporais.
"""

# usamos o 'rolling' para fazer uma janela e dai podemos
import matplotlib.pyplot as plt

plt.plot(df.ano,df.anomalia_soc,'-ok',label='original')
plt.plot(df.ano,df.anomalia_soc.rolling(3).mean(),'--sr',label='Janela=3 anos') # janela de 3 anos tirando a média
plt.xlabel('ano')
plt.ylabel('anomalia_soc')
plt.legend()

# Veja o resultado abaixo

# vamos supor agora que eu queira ver como a "Variância" se comporta no tempo
import matplotlib.pyplot as plt

#plt.plot(df.Ano,df.SOC,'-ok',label='original')
plt.plot(df.ano,(df.anomalia_soc.rolling(10).std())**2,'--sr',label='Janela=10 anos') # janela de 10 anos tirando a média
plt.xlabel('Ano')
plt.ylabel('Variância do SOC')
plt.legend()

"""## MUITO IMPORTANTE ##

A Análise de Componentes Principais é uma análise de exploração de dados e não um "plug-and-play" que responde todas as suas dúvidas de vida. É importante você prestar a atenção a partir daqui para ver que você deve ir para frente e para trás, refazendo isso várias vezes e formando suas hipóteses conforme você explora os dados. **Fique atento**.
"""

# Como eu quer usar apenas parte dos meus dados, sem mexer com o dataframe original
# é aqui que eu seleciono o que eu vou usar na minha PCA

df2 = df # Aqui eu poderia cortar alguns anos, porém vou seguir com a série histórica
series = df2['ano']

# esta é uma maneira "não muito" eficiente de tranformar o resultado da tabela em números
# mas funciona sem que você tenha que mexer muito no seu arquivo/dados originais
mydata = df2[[ 'anomalia_soc', 'Classe_1', 'Classe_2', 'Classe_4', 'Classe_6','Classe_7', 'Classe_8', 'Classe_9', 'Classe_10', 'Classe_11','aet_sum', 'def_sum', 'pet_sum', 'ppt_sum', 'q_sum', 'srad_sum', 'tmax_sum', 'tmin_sum', 'vap_sum', 'vpd_sum', 'ws_sum'
]]

# agora junto as duas de novo para facilitar a produção de gráficos
frame = pd.concat([series,mydata],axis=1) # <---- cautela: se você quer analisar mydata2

# posso olhar como ficou aqui
frame.head()
#frame.tail()

# note que aqui eu posso verificar que não há uma correlação aparente.
fig = plt.figure()

# Paleta de cores variada
colors = ['b', 'r', 'g', 'y', 'k', 'c', 'm', '#FF5733', '#33FF57', '#3357FF', '#FF33A8', '#A833FF', '#FFAA33']

# Criar o gráfico de dispersão
ax = frame.plot(kind='scatter', x='Classe_1', y='anomalia_soc', color=colors[0], label='C1')
frame.plot(kind='scatter', x='Classe_2', y='anomalia_soc', color=colors[2], label='C2', ax=ax)
frame.plot(kind='scatter', x='Classe_4', y='anomalia_soc', color=colors[3], label='C4', ax=ax)
frame.plot(kind='scatter', x='Classe_6', y='anomalia_soc', color=colors[4], label='C6', ax=ax)
frame.plot(kind='scatter', x='Classe_7', y='anomalia_soc', color=colors[9], label='C7', ax=ax)
frame.plot(kind='scatter', x='Classe_8', y='anomalia_soc', color=colors[5], label='C8', ax=ax)
frame.plot(kind='scatter', x='Classe_9', y='anomalia_soc', color=colors[6], label='C9', ax=ax)
frame.plot(kind='scatter', x='Classe_10', y='anomalia_soc', color=colors[7], label='C10', ax=ax)
frame.plot(kind='scatter', x='Classe_11', y='anomalia_soc', color=colors[8], label='C11', ax=ax)

# Adicionar título e rótulos aos eixos
plt.title('Gráfico de Dispersão dos Componentes')
plt.xlabel('Componentes')
plt.ylabel('Anomalia SOC')

# Exibir legenda
plt.legend()

# Mostrar o gráfico
plt.show()

import numpy as np
# para verificar a média, mediana e desvio do rendimento
print('media anomalia_soc=',np.average(frame['anomalia_soc']))
mymean = np.average(frame['anomalia_soc'])
print('Correlação SOC vs classe_1=',np.corrcoef(frame['anomalia_soc'],frame['Classe_1'])[0,1])
# se quiser saber mais sobre correlações, clique aqui https://benalexkeen.com/correlation-in-python

"""Agora analisamos a série histórica"""

import matplotlib.pyplot as plt

# Paleta de cores variada
colors = ['#1f8d49', '#d6bc74', '#edde8e', '#C27BA0', '#d082de', '#7a5900', '#ffefc3', '#d4271e', '#2532e4', '#3357FF', '#FF33A8', '#A833FF','#FFAA33']

# Agora quero ver uma série temporal
fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 8))
fig.suptitle("anomalia_soc")

# Plot para ax1
frame.plot(x='ano', y='Classe_1', color=colors[0], label='Floresta', ax=ax1)
frame.plot(x='ano', y='Classe_2', color=colors[1], label='Formação Natural Não Florestal', ax=ax1)
frame.plot(x='ano', y='Classe_4', color=colors[10], label='Pastagem', ax=ax1)
frame.plot(x='ano', y='Classe_6', color=colors[3], label='Lavoura Temporária', ax=ax1)
frame.plot(x='ano', y='Classe_7', color=colors[4], label='Lavoura Perene', ax=ax1)
frame.plot(x='ano', y='Classe_8', color=colors[5], label='silvicultura', ax=ax1)
frame.plot(x='ano', y='Classe_9', color=colors[9], label='Mosaicos de uso', ax=ax1)
frame.plot(x='ano', y='Classe_10', color=colors[7], label='área não vegetada', ax=ax1)
frame.plot(x='ano', y='Classe_11', color=colors[4], label='corpos de água', ax=ax1)

ax1.set_ylabel("área de cada classe")
ax1.legend(bbox_to_anchor=(1.1, 1.05))

# Plot para ax2
frame.plot(x='ano', y='anomalia_soc', color='k', label='anomalia_soc', ax=ax2)

ax2.set_xlabel("Ano")
ax2.set_ylabel("Anomalia SOC")
ax2.legend()

# Mostrar o gráfico
plt.show()

"""Outro método de correlação"""

# ainda posso fazer a correlação usando outros métodos. Veja aqui https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html
frame.iloc[:,1:-1].corr(method='pearson')

# o segundo parâmetro "iloc" está selecionando todas as linhas e as colunas 1 até o final
frame.iloc[:,1:-1].corr(method='kendall')

"""Note que em uma das células usamos o método "Pearson" e na outra "Kendall". Você PRECISA saber o que isso significa. Demonstrei em aula como estudar isso.

# Parte 2 - Agora é PCA pura !

PCA é uma técnica de redução de dimensão que pega um conjunto de variáveis possivelmente correlacionadas e se transforma em componentes principais linearmente não correlacionados. É usado para enfatizar variações e destacar padrões fortes em um conjunto de dados. <br>

Em palavras simples, a **análise de componentes principais** é um método de extrair variáveis importantes de um grande conjunto de variáveis disponíveis em um conjunto de dados. Ele extrai um conjunto de características de baixa dimensão de um conjunto de dados de alta dimensão com o objetivo de capturar o máximo de informações possível.<br>
<figure>
<figcaption align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/f/f5/GaussianScatterPCA.svg" width="200"><br> Exemplo de uma distribuição de dados na PCA</figcaption>
</figure>

Esta parte do notebook tem como objetivo visualizar os principais componentes usando Python. Você pode encontrar explicações matemáticas nos links fornecidos ao longo do texto. Acima desta parte seus dados já estão na memória e prontos para usar

Vamos começar!
"""

mydata.info()

# todos os nossos dados estão agora na DataFrame "mydata" (incluindo o rendimento)

from sklearn.preprocessing import StandardScaler
x = StandardScaler().fit_transform(mydata) # <<<<------ Mude aqui e abaixo para mydata2 se quiser retirar o SOC
x = pd.DataFrame(x, columns=mydata.columns) # aqui criou o dataset X já padronizado e com os mesmos nomes de mydata
x.head() # caso você queira ver como ficou, descomente isso.

"""## Obtendo as componentes da PCA
O cálculo do PCA envolve as seguintes etapas:

* Calcular a [matriz de covariância](https://pt.wikipedia.org/wiki/Matriz_de_covari%C3%A2ncia)
* Calcular os [autovalores e autovetores](https://pt.wikipedia.org/wiki/Autovalores_e_autovetores)
* Formar as Componentes Principais
* Projetar para o novo espaço de componentes

Aqui vamos focar na visualização e interpretação das componentes da PCA e, felizmente, o sklearn fornece o módulo PCA para obter os componentes da PCA. Porém, para aprender mais, siga os links acima.

Em PCA(), `n_components` especifica quantos componentes são retornados após o ajuste e a transformação. O número máximo de componentes depende do número de variáveis. Porém nosso cérebro tem mais facilidade de entender até 3 componentes (afinal, somos seres inteligentes mas ainda no espaço tridimensional).

"""

from sklearn.decomposition import PCA
import numpy as np
pcamodel = PCA(n_components=3) #<--- aqui é que você controla o número de componentes
pca = pcamodel.fit_transform(x)
pca.shape # note que ele vai te mostrar o número de linhas e de componentes

"""## Gráficos de atributos do modelo da PCA
Os componentes do PCA e sua importância podem ser explicados usando os seguintes atributos:
* A **variação explicada** é a quantidade de variação explicada por cada um dos componentes selecionados. Este atributo está associado ao modelo sklearn PCA, conforme `explained_variance_`
* A **razão de variância explicada** é a porcentagem da variância explicada por cada um dos componentes selecionados. Seu atributo é `explained_variance_ratio_`

Nota sobre a *explained_variance_*: Este atributo retorna a variância (dispersão) de cada uma das componentes principais. Especificamente, é a quantidade de variância que cada componente principal captura dos dados originais e ela é dada **nas mesmas unidades** dos dados originais (ou seja, não é uma proporção ou porcentagem, mas a quantidade real de variância explicada por cada componente). Como normalizamos nossas variáveis, essa unidade não tem muito o que explicar já que é a quantidade absoluta de variância capturada por cada componente principal. Valores maiores indicam que a componente captura mais variação dos dados originais.<br>

Já a *explained_variance_ratio_* é uma proporção ou percentual, representando quanto da variância total dos dados é capturada por cada componente principal. Em outras palavras, é a variância explicada por cada componente dividida pela variância total dos dados.
"""

pcamodel.explained_variance_

# ****** esta é a parte mais importante *******
# ela diz quanto cada componente explica de variância em seu sistema.
pcamodel.explained_variance_ratio_

pcamodel.explained_variance_ratio_.sum() # isso é a explicação de variância total

"""Hummm...isso é bom ou ruim ? Note que não esperamos valores muito > que 50% (ou seja, 0.5) mas tenha cautela se seus valores foram muito altos (por exemplo> 0.8 ou 80%).

Dificil de guardar o que significam, mas nada que vocês não possam estudar mais. Porém, para ficar mais interessante vamos plotar isso.
"""

import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator
import numpy as np

# Dados para o gráfico
components = np.arange(1, len(pcamodel.explained_variance_ratio_) + 1)
explained_variance = pcamodel.explained_variance_ratio_
cumulative_variance = np.cumsum(explained_variance)

# Criando a figura e os eixos
fig, ax1 = plt.subplots()

# Gráfico de barras para variância explicada
ax1.bar(components, explained_variance, alpha=0.7, label='Variância Explicada')
ax1.set_xlabel('Componentes')
ax1.set_ylabel('Variância Explicada')
ax1.set_title('Variância Explicada por Componente Principal')
ax1.xaxis.set_major_locator(MaxNLocator(integer=True))

# Gráfico de linha para variância explicada acumulada
ax2 = ax1.twinx()  # Cria um segundo eixo que compartilha o mesmo eixo x
ax2.plot(components, cumulative_variance, color='red', marker='o', linestyle='-', label='Variância Explicada Acumulada')
ax2.plot(components, explained_variance, color='green', marker='o', linestyle='-', label='Variância Explicada (ratio)')
ax2.set_ylabel('Variância Explicada Acumulada', color='red')

# Adicionando legendas
fig.legend(loc='upper left', bbox_to_anchor=(1.1,0.9))

# Melhorando a estética do gráfico
ax1.grid(True)
fig.tight_layout()

# Exibindo o gráfico
plt.show()

"""Você deve ter encontrado que a PC-1 explica a maior parte da variação do que os componentes subsequentes. Em outras palavras, a maioria dos recursos são explicados e abrangidos pelo PC-1. Ela que determina quem se alinha com quem (ou quem está mais correlacionado com quem).<br>
## Gráfico de dispersão de PCA1 e PCA2
`pca` contém todos os componentes do PCA. Os dois primeiros deles podem ser visualizados usando o gráfico de dispersão simples. Você pode mudar para a componente que quiser. Isso ajuda a entender a dispersão dos dados.<br>
(nota para os monitores: vamos depois implementar a vizualização 3D aqui https://plotly.com/python/3d-scatter-plots/)
"""

plt.scatter(pca[:, 0], pca[:, 2]) # lembre-se que PC1 é 0, PC2 é 1, etc

"""## Efeito das variáveis em cada componente
O atributo `components_` fornece eixos principais no espaço da PCA, representando as direções de variação máxima nos dados. Isso significa que podemos ver a influência em cada um dos componentes na variância total. Note que os dados foram padronizados, então essa influência é um pouco diferente do que a que vimos lá em cima.
"""

pcamodel.components_.max()

"""Uma maneira de observar quem se correlaciona com quem é através de um heatmap."""

import matplotlib.pyplot as plt
import seaborn as sns

fig, ax = plt.subplots(figsize=(10, 8))  # Ajuste o tamanho da figura conforme necessário

sns.heatmap(pcamodel.components_,
            cmap='RdBu_r',
            yticklabels=["PCA" + str(x) for x in range(1, pcamodel.n_components_ + 1)],
            xticklabels=list(x.columns),
            cbar_kws={"orientation": "horizontal"},
            vmin=-1, vmax=1,
            ax=ax)

ax.xaxis.set_ticks_position('top')  # Coloca os xlabels no topo
ax.set_aspect("equal")
plt.xticks(rotation=90)  # Escreve os xticks na vertical

# Ajusta as margens para dar mais espaço no eixo y
plt.subplots_adjust(left=0.15, right=0.95, top=0.85, bottom=0.15)

plt.show()

"""## PCA Biplot
Biplot é um tipo de análise interessante e contém muitas informações úteis.

Ele contém dois gráficos:

* Gráfico de dispersão da PCA que mostra os dois primeiros componentes (já traçamos isso acima)
* Gráfico de carregamento (loadings) da PCA que mostra o quão fortemente cada característica influencia um componente principal.

**PCA Loading Plot**: Todos os vetores começam na origem e seus valores projetados nos componentes explicam quanto peso eles têm naquele componente. Além disso, os ângulos entre os vetores individuais informam sobre a correlação entre eles.

Aprenda mais sobre o biplot [aqui](http://www.nonlinear.com/support/progenesis/comet/faq/v2.0/pca.aspx)
"""

import matplotlib.pyplot as plt
import numpy as np

# Esta é apenas uma subrotina para plotar
def myplotPCA(score, coeff, labels=None, data=None):
    plt.figure(figsize=(15, 10))  # Aqui controla o tamanho da figura
    xs = score[:, 0]  # Aqui pega o score da componente 1
    ys = score[:, 1]  # Aqui pega o score da componente 2
    n = coeff.shape[0]
    scalex = 1 / (xs.max() - xs.min())  # Isso aqui é para que todos os dados estejam na mesma escala normalizada
    scaley = 1 / (ys.max() - ys.min())

    # Scatter plot com coloração baseada em 'Rendimento', se fornecido
    if data is not None:
        plt.scatter(xs * scalex, ys * scaley, s=50, c=data['anomalia_soc'], cmap='rainbow')
        plt.colorbar()
    else:
        plt.scatter(xs * scalex, ys * scaley, s=50)

    for i in range(n):
        # Usando plt.quiver para adicionar cabeças de seta
        plt.quiver(0, 0, coeff[i, 0], coeff[i, 1], angles='xy', scale_units='xy', scale=1, color='r', alpha=0.5)
        if labels is None:
            plt.text(coeff[i, 0] * 1.15, coeff[i, 1] * 1.15, "Var" + str(i + 1), color='green', ha='center', va='center')
        else:
            plt.text(coeff[i, 0] * 1.15, coeff[i, 1] * 1.15, labels[i], color='g', ha='center', va='center')

    plt.xlabel("PC{}".format(1))
    plt.ylabel("PC{}".format(2))
    plt.grid()
    #plt.xlim([-1, 1])
    #plt.ylim([-1, 1])

# ---- Aqui termina a função de plot

# Aqui é que faz a PCA e é aqui que eu seleciono os meus dados
# Supondo que 'pca' e 'pcamodel' já tenham sido definidos anteriormente
# E que 'frame' é o DataFrame contendo a coluna 'Rendimento'
myplotPCA(pca[:, 0:2], np.transpose(pcamodel.components_[0:2, :]), list(x.columns), data=frame)
plt.show()

"""#Agora podemos refinar os resultados
O que preciso é que sejam feitas as novas classes:

- Floresta: Quando o valor for 1,3, 4, 5, 6 e/ou 49, a célula assuma o valor de 1
- Formação Natural não Florestal: Quando o valor for 10,11,12, 32, 29,50 assuma o valor de 2
- Agropecuária: Quando o valor for 14 assuma o valor de 3
- Pastagem: Quando o valor for 15 assuma o valor de 4
- Agricultura: Quando o valor for 18 assuma o valor de 5
- Lavoura Temporária: Quando o valor for 19,39,20, 40, 62 e/ou 41 assuma o valor de 6
- Lavoura Perene: Quando o valor for de 36,46, 47, 35 e/ou 48 assuma o valor de 7
- Silvicultura: Quando o valor for 9 assumir o valor de 8
- Mosaico de Usos: Quando o valor for 21 assumir o valor de 9
- Área não Vegetada: Quando o valor for 22,23,24, 30 e/ou 25 assumir o valor de 10
- Corpo D'água: Quando o valor for 26,33 e/ou 31 assumir o valor de 11
- Não observado: Quando o valor for 27 ou qualquer outro assumir o valor de 12
"""

# agora fazendo tudo junto

#mydata2 = mydata [['anomalia_soc','classe_2', 'classe_9', 'classe_11','classe_1','classe_10','classe_6','ppt_sum','pet_sum']]
#mydata2.columns = ['Anom_Soc','For_Natural','Mosaico','Água','Floresta','Cidade/Solo','Lavoura','Q_precip_anom','Q_evap_anom']
mydata2 = mydata [['anomalia_soc','Classe_1', 'Classe_2','Classe_6','Classe_7','Classe_8','Classe_9','Classe_10','Classe_11','ppt_sum','pet_sum','srad_sum']]
mydata2.columns = ['Anom_Soc','Floresta','For_Natural','Lavoura_Temp','Lavoura_Pere','Silvicultura','mosaicos_uso','urbano/solo','água','Q_precip_anom','Q_evap_anom','Q_radia']

from sklearn.preprocessing import StandardScaler
x = StandardScaler().fit_transform(mydata2) # <<<<------ Mude aqui e abaixo para mydata2 se quiser retirar o SOC
x = pd.DataFrame(x, columns=mydata2.columns) # aqui criou o dataset X já padronizado e com os mesmos nomes de mydata
#x.head() # caso você queira ver como ficou, descomente isso.

from sklearn.decomposition import PCA
import numpy as np
pcamodel = PCA(n_components=3) #<--- aqui é que você controla o número de componentes
pca = pcamodel.fit_transform(x)
#pca.shape # note que ele vai te mostrar o número de linhas e de componentes

# Verificar a variância explicada por cada componente
variancia_explicada = pcamodel.explained_variance_ratio_

# Calcular a variância total explicada
variancia_total_explicada = variancia_explicada.sum()

# Exibir os resultados
print("Variância explicada por componente:")
for i, variancia in enumerate(variancia_explicada, 1):
    print(f"PC{i}: {variancia:.4f}")

print(f"\nVariância total explicada: {variancia_total_explicada:.4f}")

import matplotlib.pyplot as plt
import numpy as np

# Função atualizada para permitir escolha de PCs
def myplotPCA(score, coeff, labels=None, data=None, PCPLOT=(1, 2)):
    """
    Plota um gráfico de PCA, permitindo selecionar os PCs nos eixos X e Y.

    Parâmetros:
        score: array com os scores das componentes principais.
        coeff: array com os coeficientes das componentes principais.
        labels: lista de rótulos para variáveis.
        data: DataFrame com dados adicionais, usado para coloração.
        PCPLOT: tupla indicando os PCs a serem usados nos eixos (default: (1, 2)).
    """
    plt.figure(figsize=(10, 8))  # Tamanho da figura

    # Ajustar os índices para base zero
    pcx, pcy = PCPLOT[0] - 1, PCPLOT[1] - 1

    # Selecionar os scores para os PCs especificados
    xs = score[:, pcx]
    ys = score[:, pcy]
    n = coeff.shape[0]

    # Escalamento para normalização
    scalex = 1.0 / (xs.max() - xs.min())
    scaley = 1.0 / (ys.max() - ys.min())

    # Definir os limites simétricos se os dados forem fornecidos
    if data is not None and 'Anom_Soc' in data:
        vmax = max(abs(data['Anom_Soc']))
        vmin = -vmax  # Simetria em torno de zero
        plt.scatter(xs * scalex, ys * scaley, s=50, c=data['Anom_Soc'], cmap='coolwarm', vmin=vmin, vmax=vmax)
        plt.colorbar()
    else:
        plt.scatter(xs * scalex, ys * scaley, s=50)

    # Adicionar vetores das variáveis
    for i in range(n):
        plt.quiver(0, 0, coeff[i, pcx], coeff[i, pcy], angles='xy', scale_units='xy', scale=1, color='r', alpha=0.5)
        if labels is None:
            plt.text(coeff[i, pcx] * 1.15, coeff[i, pcy] * 1.15, "Var" + str(i + 1), color='green', ha='center', va='center')
        else:
            plt.text(coeff[i, pcx] * 1.15, coeff[i, pcy] * 1.15, labels[i], color='g', ha='center', va='center')

    # Configurar os eixos e título
    plt.xlabel(f"PC{PCPLOT[0]}")
    plt.ylabel(f"PC{PCPLOT[1]}")
    plt.grid()
    plt.xlim([-1, 1])
    plt.ylim([-1, 1])

import matplotlib.pyplot as plt
import seaborn as sns

def plot_pca_heatmap(pca_components, feature_names, n_components, figsize=(10, 8), cmap='RdBu_r', vmin=-1, vmax=1):
    """
    Plota um heatmap dos componentes principais do PCA.

    Parâmetros:
        pca_components (array): Componentes do PCA (geralmente `pcamodel.components_`).
        feature_names (list): Lista com os nomes das variáveis (geralmente `x.columns`).
        n_components (int): Número de componentes principais no PCA.
        figsize (tuple): Tamanho da figura (default: (10, 8)).
        cmap (str): Colormap para o heatmap (default: 'RdBu_r').
        vmin (float): Valor mínimo para a escala de cores (default: -1).
        vmax (float): Valor máximo para a escala de cores (default: 1).
    """
    fig, ax = plt.subplots(figsize=figsize)  # Configura o tamanho da figura

    sns.heatmap(
        pca_components,
        cmap=cmap,
        yticklabels=["PCA" + str(x) for x in range(1, n_components + 1)],
        xticklabels=feature_names,
        cbar_kws={"orientation": "horizontal"},
        vmin=vmin, vmax=vmax,
        ax=ax
    )

    ax.xaxis.set_ticks_position('top')  # Coloca os xlabels no topo
    ax.set_aspect("equal")
    plt.xticks(rotation=90)  # Escreve os xticks na vertical

    # Ajusta as margens para dar mais espaço no eixo y
    plt.subplots_adjust(left=0.15, right=0.95, top=0.85, bottom=0.15)

    plt.show()

plot_pca_heatmap(
    pca_components=pcamodel.components_,
    feature_names=list(x.columns),
    n_components=pcamodel.n_components_,
    figsize=(10, 8),
    cmap='RdBu_r',
    vmin=-1,
    vmax=1
)

# ---- Aqui termina a função de plot

# Aqui é que faz a PCA e é aqui que eu seleciono os meus dados
# Supondo que 'pca' e 'pcamodel' já tenham sido definidos anteriormente
# E que 'frame' é o DataFrame contendo a coluna 'Rendimento'
frame = pd.concat([series,mydata2],axis=1)

myplotPCA(pca, np.transpose(pcamodel.components_), labels=list(x.columns), data=frame, PCPLOT=(1, 2))
plt.show()

myplotPCA(pca, np.transpose(pcamodel.components_), labels=list(x.columns), data=frame, PCPLOT=(2, 3))
plt.show()

myplotPCA(pca, np.transpose(pcamodel.components_), labels=list(x.columns), data=frame, PCPLOT=(1, 3))
plt.show()

# agora fazendo tudo junto
#mydata2 = mydata [['anomalia_soc','classe_2', 'classe_9', 'classe_11','classe_1','classe_10','classe_6','ppt_sum','pet_sum']]

mydata3 = mydata [['anomalia_soc','Classe_1', 'Classe_2','Classe_6','Classe_9','Classe_10','ppt_sum','pet_sum']]
mydata3.columns = ['Anomalia SOC','Floresta','Formação Natural Não Florestal','Lavoura Temporária','Mosaicos de Usos','Área Não Vegetada','Precipitação','Evaporação',]

from sklearn.preprocessing import StandardScaler
x = StandardScaler().fit_transform(mydata3) # <<<<------ Mude aqui e abaixo para mydata2 se quiser retirar o SOC
x = pd.DataFrame(x, columns=mydata3.columns) # aqui criou o dataset X já padronizado e com os mesmos nomes de mydata
#x.head() # caso você queira ver como ficou, descomente isso.

from sklearn.decomposition import PCA
import numpy as np
pcamodel = PCA(n_components=3) #<--- aqui é que você controla o número de componentes
pca = pcamodel.fit_transform(x)
#pca.shape # note que ele vai te mostrar o número de linhas e de componentes

# Verificar a variância explicada por cada componente
variancia_explicada = pcamodel.explained_variance_ratio_

# Calcular a variância total explicada
variancia_total_explicada = variancia_explicada.sum()

# Exibir os resultados
print("Variância explicada por componente:")
for i, variancia in enumerate(variancia_explicada, 1):
    print(f"PC{i}: {variancia:.4f}")

print(f"\nVariância total explicada: {variancia_total_explicada:.4f}")

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def plot_pca_heatmap_with_values(pca_components, feature_names, n_components, figsize=(10, 8), cmap='RdBu_r', vmin=-1, vmax=1):
    """
    Plota um heatmap dos componentes principais do PCA com os valores no centro de cada célula.

    Parâmetros:
        pca_components (array): Componentes do PCA (geralmente `pcamodel.components_`).
        feature_names (list): Lista com os nomes das variáveis (geralmente `x.columns`).
        n_components (int): Número de componentes principais no PCA.
        figsize (tuple): Tamanho da figura (default: (10, 8)).
        cmap (str): Colormap para o heatmap (default: 'RdBu_r').
        vmin (float): Valor mínimo para a escala de cores (default: -1).
        vmax (float): Valor máximo para a escala de cores (default: 1).
    """
    fig, ax = plt.subplots(figsize=figsize)  # Configura o tamanho da figura

    # Plot do heatmap com anotação de valores
    sns.heatmap(
        pca_components[:n_components],
        cmap=cmap,
        annot=np.round(pca_components[:n_components], 2),  # Adiciona os valores arredondados
        fmt="",  # Remove formatação adicional do Seaborn
        yticklabels=[f"PCA{x+1}" for x in range(n_components)],
        xticklabels=feature_names,
        cbar_kws={"label": "Explicação da Variância"},
        vmin=vmin,
        vmax=vmax,
        ax=ax
    )

    # Configuração dos rótulos dos eixos
    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)  # Mantém os rótulos do eixo Y "em pé"
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)  # Rotaciona os rótulos do eixo X para vertical

    # Ajuste do layout
    plt.tight_layout()

    # Exibir o gráfico
    plt.show()

plot_pca_heatmap_with_values(
    pca_components=pcamodel.components_,
    feature_names=list(x.columns),  # Substitua pelos nomes das variáveis, se necessário
    n_components=pcamodel.n_components_,
    figsize=(10, 7),
    cmap='RdBu_r',
    vmin=-1,
    vmax=1
)

# ---- Aqui termina a função de plot

# Aqui é que faz a PCA e é aqui que eu seleciono os meus dados
# Supondo que 'pca' e 'pcamodel' já tenham sido definidos anteriormente
# E que 'frame' é o DataFrame contendo a coluna 'Rendimento'

frame = pd.concat([series, mydata2], axis=1)

# Chamada da função para plotar o gráfico PCA
myplotPCA(pca, np.transpose(pcamodel.components_), labels=list(x.columns), data=frame, PCPLOT=(1, 2))

# Adicionar rótulo à barra de cores existente
cbar = plt.gcf().axes[-1]  # Obtém o último eixo (a barra de cor)
cbar.set_ylabel("Z-Score da Anomalia de SOC", rotation=90, labelpad=15)

# Exibir o gráfico
plt.show()

myplotPCA(pca, np.transpose(pcamodel.components_), labels=list(x.columns), data=frame, PCPLOT=(2, 3))
# Adicionar rótulo à barra de cores existente
cbar = plt.gcf().axes[-1]  # Obtém o último eixo (a barra de cor)
cbar.set_ylabel("Z-Score da Anomalia de SOC", rotation=90, labelpad=15)

# Exibir o gráfico
plt.show()

myplotPCA(pca, np.transpose(pcamodel.components_), labels=list(x.columns), data=frame, PCPLOT=(1, 3))
# Adicionar rótulo à barra de cores existente
cbar = plt.gcf().axes[-1]  # Obtém o último eixo (a barra de cor)
cbar.set_ylabel("Z-Score da Anomalia de SOC", rotation=90, labelpad=15)

# Exibir o gráfico
plt.show()